import cv2
import numpy as np

def laplacian_blend(img1, img2, mask, levels=4):
    """Laplacian pyramid blending for smooth transitions (robust to size mismatches)."""
    gpA = [img1.astype(np.float32)]
    gpB = [img2.astype(np.float32)]
    gpM = [mask.astype(np.float32) / 255.0]

    for _ in range(levels):
        gpA.append(cv2.pyrDown(gpA[-1]).astype(np.float32))
        gpB.append(cv2.pyrDown(gpB[-1]).astype(np.float32))
        gpM.append(cv2.pyrDown(gpM[-1]).astype(np.float32))

    lpA = [gpA[-1]]
    lpB = [gpB[-1]]
    for i in range(levels - 1, 0, -1):
        upA = cv2.pyrUp(gpA[i], dstsize=(gpA[i - 1].shape[1], gpA[i - 1].shape[0]))
        upB = cv2.pyrUp(gpB[i], dstsize=(gpB[i - 1].shape[1], gpB[i - 1].shape[0]))
        lpA.append(gpA[i - 1] - upA)
        lpB.append(gpB[i - 1] - upB)

    blended = []
    for la, lb, gm in zip(lpA, lpB, gpM[::-1]):
        h, w = la.shape[:2]
        lb_resized = cv2.resize(lb, (w, h))
        gm_resized = cv2.resize(gm, (w, h))
        gm_3 = cv2.merge([gm_resized, gm_resized, gm_resized])
        blended.append(la * (1 - gm_3) + lb_resized * gm_3)

    img_blend = blended[0]
    for i in range(1, len(blended)):
        img_blend = cv2.pyrUp(img_blend)
        if img_blend.shape != blended[i].shape:
            img_blend = cv2.resize(img_blend, (blended[i].shape[1], blended[i].shape[0]))
        img_blend = cv2.add(img_blend, blended[i])

    return np.clip(img_blend, 0, 255).astype(np.uint8)

# ---------------- Alignment helpers ----------------
def compute_vertical_offset_orb(left_strip, right_strip, min_matches=8):
    """Use ORB to compute the median vertical offset (dy) between left_strip and right_strip.
    Returns dy (pixels) where positive means right image should be moved down to align with left.
    If not enough matches, returns None.
    """
    # Convert to gray
    g1 = cv2.cvtColor(left_strip, cv2.COLOR_BGR2GRAY)
    g2 = cv2.cvtColor(right_strip, cv2.COLOR_BGR2GRAY)

    orb = cv2.ORB_create(1000)
    k1, d1 = orb.detectAndCompute(g1, None)
    k2, d2 = orb.detectAndCompute(g2, None)
    if d1 is None or d2 is None or len(k1) < 4 or len(k2) < 4:
        return None

    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
    matches = bf.match(d1, d2)
    if matches is None or len(matches) < min_matches:
        return None

    # Sort by distance and keep a subset to reduce outliers
    matches = sorted(matches, key=lambda x: x.distance)[:min(200, len(matches))]
    dys = []
    for m in matches:
        y1 = k1[m.queryIdx].pt[1]
        y2 = k2[m.trainIdx].pt[1]
        # dy: how much to move right down to match left
        dys.append(y1 - y2)

    if len(dys) == 0:
        return None
    # Use median to be robust
    dy = int(np.median(dys))
    return dy

def warp_image_vertically(img, dy):
    """Translate image vertically by dy pixels (positive dy shifts down)."""
    h, w = img.shape[:2]
    M = np.float32([[1, 0, 0], [0, 1, dy]])
    # keep same size; out-of-bounds will be filled by reflection to reduce seams
    warped = cv2.warpAffine(img, M, (w, h), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_REFLECT)
    return warped

# ---------------- Stitching ----------------
def find_best_overlap(img1, img2):
    """Estimate horizontal overlap using template matching (same as before)."""
    gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
    gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)
    w = min(gray1.shape[1] // 3, gray2.shape[1] // 3)
    if w < 10:
        return 0
    res = cv2.matchTemplate(gray1[:, -w:], gray2[:, :w], cv2.TM_CCOEFF_NORMED)
    _, _, _, max_loc = cv2.minMaxLoc(res)
    overlap = w - max_loc[0]
    return overlap

def stitch_images(images, debug_lines=False):
    """Stitches frames with vertical alignment based on ORB matches along edges."""
    if len(images) < 2:
        return images[0]

    panorama = images[0].copy()
    for i in range(1, len(images)):
        left = panorama
        right = images[i].copy()

        # Determine overlap width (reduced to avoid over-blending)
        raw_overlap = find_best_overlap(left, right)
        overlap = max(20, int(raw_overlap * 0.3))  # keep some minimal overlap
        min_w = min(overlap, left.shape[1], right.shape[1])
        if min_w <= 0:
            panorama = np.hstack((left, right))
            continue

        # Extract the vertical strips used for matching/alignment
        left_strip = left[:, left.shape[1] - min_w:]
        right_strip = right[:, :min_w]

        # Compute vertical offset using ORB
        dy = compute_vertical_offset_orb(left_strip, right_strip)
        if dy is not None:
            # Warp full right image vertically by dy (align it to left)
            right_warped = warp_image_vertically(right, dy)

            # Also warp the right_overlap strip consistently
            right_overlap_warped = right_warped[:, :min_w]
            # After warping, the overlapped strips may still have tiny vertical mismatches due to cropping
            # Make sure both strips have same height (crop to intersection)
            h_left = left_strip.shape[0]
            h_right = right_overlap_warped.shape[0]
            h_min = min(h_left, h_right)
            left_strip_c = left_strip[:h_min, :]
            right_strip_c = right_overlap_warped[:h_min, :]
            # Build mask for blending with height h_min
            mask = np.linspace(0, 255, min_w).astype(np.uint8)
            mask = np.tile(mask, (h_min, 1))
            blended = laplacian_blend(left_strip_c, right_strip_c, mask)
            # Build the new panorama width and fill appropriately
            # When we warped the right frame, its height is same as left (warp preserves size)
            # But we used only h_min rows of blended; we need to place the blended region at top (0)
            new_width = left.shape[1] + right_warped.shape[1] - min_w
            panorama_new = np.zeros((left.shape[0], new_width, 3), dtype=np.uint8)

            # left: everything except its overlapping strip
            panorama_new[:, :left.shape[1] - min_w] = left[:, :left.shape[1] - min_w]

            # place blended (top-aligned)
            start_x = left.shape[1] - min_w
            panorama_new[:h_min, start_x:start_x + min_w] = blended

            # place right_warped's remaining area (after its overlapped columns)
            right_remaining = right_warped[:, min_w:]
            right_start = start_x + min_w
            panorama_new[:, right_start:right_start + right_remaining.shape[1]] = right_remaining

            panorama = panorama_new

        else:
            # Fallback: no reliable vertical alignment found; use previous method but crop to equal heights
            left_strip_h = left_strip.shape[0]
            right_strip_h = right_strip.shape[0]
            h_min = min(left_strip_h, right_strip_h)
            left_strip_c = left_strip[:h_min, :]
            right_strip_c = right_strip[:h_min, :]

            mask = np.linspace(0, 255, min_w).astype(np.uint8)
            mask = np.tile(mask, (h_min, 1))
            blended = laplacian_blend(left_strip_c, right_strip_c, mask)

            new_width = left.shape[1] + right.shape[1] - min_w
            panorama_new = np.zeros((left.shape[0], new_width, 3), dtype=np.uint8)
            panorama_new[:, :left.shape[1] - min_w] = left[:, :left.shape[1] - min_w]

            start_x = left.shape[1] - min_w
            panorama_new[:h_min, start_x:start_x + min_w] = blended

            # place right remaining (align from top)
            right_remaining = right[:, min_w:]
            right_start = start_x + min_w
            panorama_new[:, right_start:right_start + right_remaining.shape[1]] = right_remaining

            panorama = panorama_new

    return panorama

# ---------------- Main ----------------
if __name__ == "__main__":
    video_path = "referencevideo.mov"
    cap = cv2.VideoCapture(video_path)
    if not cap.isOpened():
        print("Error: Cannot open video file.")
        exit()

    frames = []
    frame_skip = 60   # tweak as needed for horizontal motion
    frame_count = 0
    max_frames = 5

    while True:
        ret, frame = cap.read()
        if not ret:
            break
        if frame_count % frame_skip == 0:
            frames.append(frame.copy())
            print(f"Captured frame {len(frames)}")
        if len(frames) == max_frames:
            break
        frame_count += 1
    cap.release()

    if len(frames) < 2:
        print("Not enough frames to stitch.")
        exit()

    print("Stitching frames with vertical alignment...")
    panorama = stitch_images(frames)

    # Scale to fit screen width while preserving aspect ratio (no stretching)
    screen_width = 1280
    scale_ratio = min(1.0, screen_width / panorama.shape[1])
    display_width = int(panorama.shape[1] * scale_ratio)
    display_height = int(panorama.shape[0] * scale_ratio)
    panorama_resized = cv2.resize(panorama, (display_width, display_height))

    # Optional: draw separators for debugging (scaled positions)
    start_x = 0
    for i in range(1, len(frames)):
        raw_overlap = find_best_overlap(frames[i-1], frames[i])
        overlap = max(20, int(raw_overlap * 0.3))
        start_x += frames[i-1].shape[1] - overlap
        cv2.line(panorama_resized,
                 (int(start_x * scale_ratio), 0),
                 (int(start_x * scale_ratio), display_height - 1),
                 (0, 0, 255),
                 2)

    out_path = "video_panorama_result_aligned.jpg"
    cv2.imwrite(out_path, panorama)
    print(f"âœ… Panorama saved to {out_path}")

    cv2.imshow("Panorama (aligned)", panorama_resized)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
